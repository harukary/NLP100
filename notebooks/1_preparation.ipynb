{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "stressed = 'stressed'\n",
    "desserts = stressed[::-1]\n",
    "print(desserts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パトカー\n"
     ]
    }
   ],
   "source": [
    "patatokukashi = 'パタトクカシーー'\n",
    "extracted = [s for i, s in enumerate(patatokukashi) if i%2 == 0]\n",
    "extracted = ''.join(extracted)\n",
    "print(extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "police_car = 'パトカー'\n",
    "taxi = 'タクシー'\n",
    "patatokukashi = []\n",
    "for p,t in zip(police_car, taxi):\n",
    "    patatokukashi.append(p)\n",
    "    patatokukashi.append(t)\n",
    "patatokukashi = ''.join(patatokukashi)\n",
    "print(patatokukashi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.'\n",
    "words = sentence.split(' ')\n",
    "words_num = [len(s.replace(',','').replace('.','')) for s in words]\n",
    "print(words_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'He', 'Lied', 'Because', 'Boron', 'Could', 'Not', 'Oxidize', 'Fluorine.', 'New', 'Nations', 'Might', 'Also', 'Sign', 'Peace', 'Security', 'Clause.', 'Arthur', 'King', 'Can.']\n",
      "{'H': 0, 'He': 1, 'Li': 2, 'Be': 3, 'B': 4, 'C': 5, 'N': 6, 'O': 7, 'F': 8, 'Ne': 9, 'Na': 10, 'Mi': 11, 'Al': 12, 'Si': 13, 'P': 14, 'S': 15, 'Cl': 16, 'Ar': 17, 'K': 18, 'Ca': 19}\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.'\n",
    "first = [1,5,6,7,8,9,15,16,19]\n",
    "words = sentence.split(' ')\n",
    "print(words)\n",
    "elements = {}\n",
    "for i,s in enumerate(words):\n",
    "    if i+1 in first:\n",
    "        elements[s[0]] = i\n",
    "    else:\n",
    "        elements[''.join(s[:2])] = i\n",
    "\n",
    "print(elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n"
     ]
    }
   ],
   "source": [
    "def ngram(l,n):\n",
    "    ngram_list = []\n",
    "    for i in range(n,len(l)+1):\n",
    "        ng = l[i-n:i]\n",
    "        # print(ng)\n",
    "        ngram_list.append(ng)\n",
    "    return ngram_list\n",
    "\n",
    "sentence = 'I am an NLPer'\n",
    "words = sentence.split(' ')\n",
    "word_ngarm = ngram(words,2)\n",
    "print(word_ngarm)\n",
    "letter_ngram = ngram(sentence,2)\n",
    "print(letter_ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gr', 'ap', 'di', 'pa', 'se', 'ag', 'ph', 'ad', 'is', 'ar', 'ra'}\n",
      "{'ap', 'ar', 'ra', 'pa'}\n",
      "{'di', 'is', 'ad', 'se'}\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "paraparaparadise = 'paraparaparadise'\n",
    "paragraph = 'paragraph'\n",
    "X = ngram(paraparaparadise,2)\n",
    "Y = ngram(paragraph,2)\n",
    "X = set(X)\n",
    "Y = set(Y)\n",
    "\n",
    "and_c = X | Y\n",
    "print(and_c)\n",
    "product_c = X & Y\n",
    "print(product_c)\n",
    "diff_c = X - Y\n",
    "print(diff_c)\n",
    "\n",
    "print('se' in X)\n",
    "print('se' in Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "def template_sentence(x,y,z):\n",
    "    return f\"{str(x)}時の{str(y)}は{str(z)}\"\n",
    "\n",
    "print(template_sentence(12,'気温',22.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I szev qfhg hgzigvw NLP 100.\n"
     ]
    }
   ],
   "source": [
    "def cipher(sentence):\n",
    "    return ''.join([chr(219-ord(s)) if s.islower() else s for s in sentence])\n",
    "\n",
    "sentence = 'I have just started NLP 100.'\n",
    "print(cipher(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I clon’dut bivelee that I cloud aalcluty unndatersd what I was radeing : the pemnnhoael pewor of the huamn mind .\n"
     ]
    }
   ],
   "source": [
    "def typoglycemia(sentence):\n",
    "    words = sentence.split(' ')\n",
    "    randomed_words = []\n",
    "    for w in words:\n",
    "        if len(w) > 4:\n",
    "            w_random = w[0]\n",
    "            # print(''.join(random.sample(w[1:len(w)-1], len(w)-2)))\n",
    "            w_random += ''.join(random.sample(w[1:len(w)-1], len(w)-2))\n",
    "            w_random += w[len(w)-1]\n",
    "            w = w_random\n",
    "        randomed_words.append(w)\n",
    "    return ' '.join(randomed_words)\n",
    "\n",
    "sentence = 'I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .'\n",
    "print(typoglycemia(sentence))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5fb5365cf560380dfcc07d5149e74d1ed3f4aeab86165c2e83d2ccd592f4af0b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv39': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
